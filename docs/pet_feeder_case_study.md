# ğŸ¾ Autonomous Pet Feeder â€” Case Study

> **A course-graded mechatronics system designed from the ground up to feed pets using smart automation.**  
> From scoring criteria to iOS app integration, this case study covers our process, design decisions, integration pain points, and final product.

---

## ğŸ¯ Project Context

This project was created for a university mechatronics course, where teams were challenged to design a **smart automated system** with both required and optional functional features.

The rules were clear:
- Meet **5 mandatory design requirements** (e.g., automatic food dispensing, weight feedback, manual override, safe operation, and mobile power).
- Choose **3 optional features** from a provided list. We selected:
  - ğŸ“± **Custom mobile app control**
  - ğŸ—£ï¸ **Voice assistant integration**
  - ğŸ“Š **Real-time weight display**

Each feature added complexity and potential for bonus marks â€” but also raised the bar for integration and reliability.

---

## ğŸ§  Initial Strategy

We began by dividing responsibilities based on our teamâ€™s strengths:
- **Mustafa** handled electrical wiring, load cell calibration, and circuit reliability.
- **Raihan** took charge of 3D modeling and printing the chassis and feed mechanism.
- **Mousa (me)**: was responsible for the **entire software pipeline**, from firmware on the ESP32 to a fully functional **iOS app** and **Siri integration**.

Instead of using a basic web interface like most other teams, we wanted to push the project further into the realm of **real-world usability** by building a fully interactive mobile experience.

---

## ğŸ› ï¸ My Role

As the **lead developer and integrator**, I was responsible for:
- ğŸ“± **iOS app development** using MIT App Inventor + Swift wrappers  
- ğŸ”„ **Bluetooth communication** with the ESP32  
- âš™ï¸ **Servo control logic** and dispensing calibration  
- ğŸ§  **Siri Shortcut integration** for voice commands  
- ğŸ”Œ Full end-to-end system testing and integration  

Getting all components to talk to each other in real time â€” especially under hardware and Bluetooth constraints â€” was by far the hardest part of this build.

---

## âš ï¸ Integration Challenges

The integration phase pushed the entire system to its limits:

- **Real-time weight syncing** between the load cell and mobile app needed signal filtering and recalibration.
- **Siri Shortcuts** required custom Swift scripting and interfacing with App Inventorâ€™s limited ecosystem.
- **Bluetooth stability** was a constant issue on iOS, especially with asynchronous signals from the ESP32.
- **Race conditions** between app controls and servo movement introduced bugs that werenâ€™t easy to isolate.

Debugging this stack wasnâ€™t just about code â€” it meant physically observing behavior, rewriting logic on both sides, and implementing fail-safes to ensure the food didnâ€™t get over-dispensed or missed entirely.

---

## ğŸ“ Constraints & Challenges

- **Must use a microcontroller (ESP32) with embedded logic**
- **Bluetooth communication only** (no Wi-Fi fallback allowed)
- **Calibrate food weight precisely using a load cell**
- **All 3D parts printed in-house**
- **Battery-powered with safe operation guaranteed**
- **No external libraries for Siri â€” only native tools allowed**

---

## ğŸ§ª Testing Process

We ran dozens of test cycles using:
- ğŸ§ª **Dummy food weights** to calibrate load cell readings  
- ğŸ§ª **Servo rotation limiters** to ensure no jamming  
- ğŸ§ª **Bluetooth signal strength tests** across devices  
- ğŸ§ª **Voice command trials** under noisy conditions

Debugging was done using serial print logs and physical LEDs for state indication since we had no GUI debugging tools for ESP32.

We also ensured that **manual override** was still possible via a mechanical button in case the app or Bluetooth connection failed.

---

## ğŸ Results

By the end of the semester, our system:
- âœ… Dispensed food with precision using the servo and load cell feedback  
- âœ… Displayed real-time food weight in the mobile app  
- âœ… Was fully controllable via a Bluetooth iOS app  
- âœ… Responded to Siri commands like *"Feed the dog"* using custom voice triggers  
- âœ… Outperformed most other teams in integration complexity and polish

---

## ğŸ§  Takeaways

- Start integration **way earlier** â€” it's where everything breaks
- Cross-platform communication needs layered fallback logic
- Designing for **actual users** (like pet owners) changes the way you think
- Simpler mechanical design = smoother electronic control
- Innovation doesnâ€™t mean more features â€” it means better flow

---

## ğŸ‘¥ Team Members

- **Mousa Pirzada** â€” App Development, Firmware, System Integration  
- **Mustafa Hasan** â€” Electrical Circuitry, Load Cell Calibration  
- **Raihan Ahmed** â€” 3D Design, Printing, Mechanical Assembly

---

## ğŸ“ Related Links

- [ğŸ”— GitHub Repository](https://github.com/20mup/autonomous-pet-feeder)
- [ğŸ“¸ View Project Media Folder](https://github.com/20mup/autonomous-pet-feeder/images)
- [ğŸ  Return to Portfolio](https://github.com/20mup/20mup.github.io/projects/autonomous-pet-feeder)

---

> _Built with plastic, code, and just a little bit of kibble._ ğŸ•
